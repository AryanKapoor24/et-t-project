{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "306b4c3a",
   "metadata": {},
   "source": [
    "# Notebook LLM with RAG\n",
    "Upload a PDF of notes and ask questions using Retrieval-Augmented Generation (RAG) with a local LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4db30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pypdf faiss-cpu sentence-transformers transformers ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bce615c",
   "metadata": {},
   "source": [
    "## 1. Upload and Parse PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac04fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "uploader = widgets.FileUpload(accept='.pdf', multiple=False)\n",
    "display(uploader)\n",
    "\n",
    "def extract_pdf_text(uploaded):\n",
    "    if not uploaded.value:\n",
    "        return ''\n",
    "    file_info = next(iter(uploaded.value.values()))\n",
    "    pdf_bytes = file_info['content']\n",
    "    with open('uploaded_notes.pdf', 'wb') as f:\n",
    "        f.write(pdf_bytes)\n",
    "    reader = PyPDF2.PdfReader('uploaded_notes.pdf')\n",
    "    text = ''\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() + '\\n'\n",
    "    return text\n",
    "\n",
    "import time\n",
    "while not uploader.value:\n",
    "    time.sleep(1)\n",
    "notes_text = extract_pdf_text(uploader)\n",
    "print('Extracted', len(notes_text), 'characters from PDF.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d78d739",
   "metadata": {},
   "source": [
    "## 2. Chunk Notes and Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec7bb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "def chunk_text(text, chunk_size=500, overlap=50):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = ' '.join(words[i:i+chunk_size])\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "chunks = chunk_text(notes_text)\n",
    "print(f'Chunked into {len(chunks)} segments.')\n",
    "\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = embedder.encode(chunks, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a2ef53",
   "metadata": {},
   "source": [
    "## 3. Build Vector Store (FAISS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c889ab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(np.array(embeddings).astype('float32'))\n",
    "print('Vector store built.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e261093b",
   "metadata": {},
   "source": [
    "## 4. Ask Questions (RAG Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db1208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# Load local LLM (replace with your Mistral path or model)\n",
    "llm_model = 'mistralai/Mistral-7B-Instruct-v0.2'  # Example; use your local path if needed\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_model, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(llm_model, trust_remote_code=True)\n",
    "llm = pipeline('text-generation', model=model, tokenizer=tokenizer, max_new_tokens=256)\n",
    "\n",
    "def retrieve(query, k=3):\n",
    "    query_emb = embedder.encode([query])\n",
    "    D, I = index.search(np.array(query_emb).astype('float32'), k)\n",
    "    return [chunks[i] for i in I[0]]\n",
    "\n",
    "def rag_answer(query):\n",
    "    retrieved = retrieve(query)\n",
    "    context = '\\n'.join(retrieved)\n",
    "    prompt = f'Context:\\n{context}\\n\\nQuestion: {query}\\nAnswer:'\n",
    "    response = llm(prompt)[0]['generated_text'].split('Answer:')[-1].strip()\n",
    "    return response\n",
    "\n",
    "# Example usage:\n",
    "question = 'What is the main topic of the notes?'\n",
    "print('Q:', question)\n",
    "print('A:', rag_answer(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e95779",
   "metadata": {},
   "source": [
    "## 5. Ask Your Own Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc00ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "qbox = widgets.Text(description='Question:')\n",
    "out = widgets.Output()\n",
    "\n",
    "def on_submit(change):\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        print('Q:', qbox.value)\n",
    "        print('A:', rag_answer(qbox.value))\n",
    "\n",
    "qbox.on_submit(on_submit)\n",
    "display(qbox, out)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
